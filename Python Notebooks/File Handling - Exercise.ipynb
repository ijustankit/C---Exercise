{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7b27b506",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus condimentum sagittis lacus, laoreet'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file = open('Datasets/Sample.txt')\n",
    "file_data = file.read(100)\n",
    "file_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee78e68b",
   "metadata": {},
   "source": [
    "## Exercise 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b92f2dcc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Donec vulputate lorem tortor, nec fermentum nibh bibendum vel. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Praesent dictum luctus massa, non euismod lacus. Pellentesque condimentum dolor est, ut dapibus lectus luctus ac. Ut sagittis commodo arcu. Integer nisi nulla, facilisis sit amet nulla quis, eleifend suscipit purus. Class aptent taciti sociosqu ad litora torquent per conubia nostra, per inceptos himenaeos. Aliquam euismod ultrices lorem, sit amet imperdiet est tincidunt vel. Phasellus dictum justo sit amet ligula varius aliquet auctor et metus. Fusce vitae tortor et nisi pulvinar vestibulum eget in risus. Donec ante ex, placerat a lorem eget, ultricies bibendum purus. Nam sit amet neque non ante laoreet rutrum. Nullam aliquet commodo urna, sed ullamcorper odio feugiat id. Mauris nisi sapien, porttitor in condimentum nec, venenatis eu urna. Pellentesque feugiat diam est, at rhoncus orci porttitor non.\n",
      "\n",
      "Nulla luctus sem sit amet nisi consequat, id ornare ipsum dignissim. Sed elementum elit nibh, eu condimentum orci viverra quis. Aenean suscipit vitae felis non suscipit. Suspendisse pharetra turpis non eros semper dictum. Etiam tincidunt venenatis venenatis. Praesent eget gravida lorem, ut congue diam. Etiam facilisis elit at porttitor egestas. Praesent consequat, velit non vulputate convallis, ligula diam sagittis urna, in venenatis nisi justo ut mauris. Vestibulum posuere sollicitudin mi, et vulputate nisl fringilla non. Nulla ornare pretium velit a euismod. Nunc sagittis venenatis vestibulum. Nunc sodales libero a est ornare ultricies. Sed sed leo sed orci pellentesque ultrices. Mauris sollicitudin, sem quis placerat ornare, velit arcu convallis ligula, pretium finibus nisl sapien vel sem. Vivamus sit amet tortor id lorem consequat hendrerit. Nullam at dui risus.\n",
      "\n",
      "Vestibulum ante ipsum primis in faucibus orci luctus et ultrices posuere cubilia Curae; Lorem ipsum dolor sit amet, consectetur adipiscing elit. Sed feugiat semper velit consequat facilisis. Etiam facilisis justo non iaculis dictum. Fusce turpis neque, pharetra ut odio eu, hendrerit rhoncus lacus. Nunc orci felis, imperdiet vel interdum quis, porta eu ipsum. Pellentesque dictum sem lacinia, auctor dui in, malesuada nunc. Maecenas sit amet mollis eros. Proin fringilla viverra ligula, sollicitudin viverra ante sollicitudin congue. Donec mollis felis eu libero malesuada, et lacinia risus interdum.\n",
      "\n",
      "Etiam vitae accumsan augue. Ut urna orci, malesuada ut nisi a, condimentum gravida magna. Nulla bibendum ex in vulputate sagittis. Nulla facilisi. Nullam faucibus et metus ac consequat. Quisque tempor eros velit, id mattis nibh aliquet a. Aenean tempor elit ut finibus auctor. Sed at imperdiet mauris. Vestibulum pharetra non lacus sed pulvinar. Sed pellentesque magna a eros volutpat ullamcorper. In hac habitasse platea dictumst. Donec ipsum mi, feugiat in eros sed, varius lacinia turpis. Donec vulputate tincidunt dui ac laoreet. Sed in eros dui. Pellentesque placerat tristique ligula eu finibus. Proin nec faucibus felis, eu commodo ipsum.\n",
      "\n",
      "Integer eu hendrerit diam, sed consectetur nunc. Aliquam a sem vitae leo fermentum faucibus quis at sem. Etiam blandit, quam quis fermentum varius, ante urna ultricies lectus, vel pellentesque ligula arcu nec elit. Donec placerat ante in enim scelerisque pretium. Donec et rhoncus erat. Aenean tempor nisi vitae augue tincidunt luctus. Nam condimentum dictum ante, et laoreet neque pellentesque id. Curabitur consectetur cursus neque aliquam porta. Ut interdum nunc nec nibh vestibulum, in sagittis metus facilisis. Pellentesque feugiat condimentum metus. Etiam venenatis quam at ante rhoncus vestibulum. Maecenas suscipit congue pellentesque. Vestibulum suscipit scelerisque fermentum. Nulla iaculis risus ac vulputate porttitor.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "file = open('Datasets/Sample.txt')\n",
    "file_data = file.readline()\n",
    "print(file.readline())\n",
    "print(file.readline())\n",
    "print(file.readline())\n",
    "print(file.readline())\n",
    "print(file.readline())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30faa86f",
   "metadata": {},
   "source": [
    "- Earlier i was storing it into a variable and calling that var again and again, but that didnt work. \n",
    "- print(file_data)\n",
    "- print(file_data)\n",
    "- print(file_data)\n",
    "- print(file_data)\n",
    "- beacause that stored the same value again and again.\n",
    "when we call this function again and again, then it stored each line in sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d4e8eff",
   "metadata": {},
   "source": [
    "### Exercise 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fd00341e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus condimentum sagittis lacus, laoreet luctus ligula laoreet ut. Vestibulum ullamcorper accumsan velit vel vehicula. Proin tempor lacus arcu. Nunc at elit condimentum, semper nisi et, condimentum mi. In venenatis blandit nibh at sollicitudin. Vestibulum dapibus mauris at orci maximus pellentesque. Nullam id elementum ipsum. Suspendisse cursus lobortis viverra. Proin et erat at mauris tincidunt porttitor vitae ac dui.\n",
      "\n",
      "Donec vulputate lorem tortor, nec fermentum nibh bibendum vel. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Praesent dictum luctus massa, non euismod lacus. Pellentesque condimentum dolor est, ut dapibus lectus luctus ac. Ut sagittis commodo arcu. Integer nisi nulla, facilisis sit amet nulla quis, eleifend suscipit purus. Class aptent taciti sociosqu ad litora torquent per conubia nostra, per inceptos himenaeos. Aliquam euismod ultrices lorem, sit amet imperdiet est tincidunt vel. Phasellus dictum justo sit amet ligula varius aliquet auctor et metus. Fusce vitae tortor et nisi pulvinar vestibulum eget in risus. Donec ante ex, placerat a lorem eget, ultricies bibendum purus. Nam sit amet neque non ante laoreet rutrum. Nullam aliquet commodo urna, sed ullamcorper odio feugiat id. Mauris nisi sapien, porttitor in condimentum nec, venenatis eu urna. Pellentesque feugiat diam est, at rhoncus orci porttitor non.\n",
      "\n",
      "Nulla luctus sem sit amet nisi consequat, id ornare ipsum dignissim. Sed elementum elit nibh, eu condimentum orci viverra quis. Aenean suscipit vitae felis non suscipit. Suspendisse pharetra turpis non eros semper dictum. Etiam tincidunt venenatis venenatis. Praesent eget gravida lorem, ut congue diam. Etiam facilisis elit at porttitor egestas. Praesent consequat, velit non vulputate convallis, ligula diam sagittis urna, in venenatis nisi justo ut mauris. Vestibulum posuere sollicitudin mi, et vulputate nisl fringilla non. Nulla ornare pretium velit a euismod. Nunc sagittis venenatis vestibulum. Nunc sodales libero a est ornare ultricies. Sed sed leo sed orci pellentesque ultrices. Mauris sollicitudin, sem quis placerat ornare, velit arcu convallis ligula, pretium finibus nisl sapien vel sem. Vivamus sit amet tortor id lorem consequat hendrerit. Nullam at dui risus.\n",
      "\n",
      "Vestibulum ante ipsum primis in faucibus orci luctus et ultrices posuere cubilia Curae; Lorem ipsum dolor sit amet, consectetur adipiscing elit. Sed feugiat semper velit consequat facilisis. Etiam facilisis justo non iaculis dictum. Fusce turpis neque, pharetra ut odio eu, hendrerit rhoncus lacus. Nunc orci felis, imperdiet vel interdum quis, porta eu ipsum. Pellentesque dictum sem lacinia, auctor dui in, malesuada nunc. Maecenas sit amet mollis eros. Proin fringilla viverra ligula, sollicitudin viverra ante sollicitudin congue. Donec mollis felis eu libero malesuada, et lacinia risus interdum.\n",
      "\n",
      "Etiam vitae accumsan augue. Ut urna orci, malesuada ut nisi a, condimentum gravida magna. Nulla bibendum ex in vulputate sagittis. Nulla facilisi. Nullam faucibus et metus ac consequat. Quisque tempor eros velit, id mattis nibh aliquet a. Aenean tempor elit ut finibus auctor. Sed at imperdiet mauris. Vestibulum pharetra non lacus sed pulvinar. Sed pellentesque magna a eros volutpat ullamcorper. In hac habitasse platea dictumst. Donec ipsum mi, feugiat in eros sed, varius lacinia turpis. Donec vulputate tincidunt dui ac laoreet. Sed in eros dui. Pellentesque placerat tristique ligula eu finibus. Proin nec faucibus felis, eu commodo ipsum.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "file = open('Datasets/Sample.txt')\n",
    "file_data = file.readlines()\n",
    "\n",
    "for i in range(5):\n",
    "    print(file_data[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9de6bd8",
   "metadata": {},
   "source": [
    "### Exercise 4 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c3e3ae4f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017 1 2 Afghanistan South Asia Takhta Pul 31.320556 65.961111 Hostage Taking (Kidnapping) 0.0 0.0 Construction Workers Taliban Business Firearms 0.0 \n",
      "2017 1 3 Sudan Sub-Saharan Africa Fantaga 12.921007000000001 24.318324 Armed Assault 2.0 0.0 Civilians: Haroun Yousif, Hamid Ibrahim Unknown Private Citizens & Property Firearms 2.0 \n",
      "2017 1 1 Democratic Republic of the Congo Sub-Saharan Africa Saboko 1.452372 29.875162 Armed Assault 7.0 0.0 Village Allied Democratic Forces (ADF) Private Citizens & Property Melee 7.0 "
     ]
    }
   ],
   "source": [
    "import csv\n",
    "file = open('Datasets/year2017.csv')\n",
    "file_data = csv.reader(file)\n",
    "\n",
    "file_list = list(file_data)\n",
    "\n",
    "# print(file_list[1])\n",
    "# print(file_list[2])\n",
    "# print(file_list[3])\n",
    "\n",
    "for i in file_list[1]:\n",
    "    print(i, end=\" \")\n",
    "    \n",
    "print()\n",
    "for i in file_list[2]:\n",
    "    print(i, end=\" \")\n",
    "\n",
    "print()\n",
    "for i in file_list[3]:\n",
    "    print(i, end=\" \")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "133e8ae8",
   "metadata": {},
   "source": [
    "### Exercise 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c0ea6c8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Afghanistan\n",
      "Sudan\n",
      "Democratic Republic of the Congo\n",
      "Democratic Republic of the Congo\n",
      "Turkey\n",
      "Syria\n",
      "Pakistan\n",
      "Italy\n",
      "Turkey\n",
      "Turkey\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "for row in file_list[1:]:\n",
    "    print(row[3])\n",
    "    if i==9:\n",
    "        break\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f88aaac",
   "metadata": {},
   "source": [
    "### Exercise 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "16c7f19f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24927\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "file = open('Datasets/year2017.csv')\n",
    "file_data = csv.reader(file)\n",
    "\n",
    "file_list = list(file_data)\n",
    "\n",
    "total = []\n",
    "for row in file_list[1:]:\n",
    "    val = row[10]\n",
    "    if val != '':\n",
    "        total.append(int(float(val)))\n",
    "\n",
    "print(sum(total))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "650f1be8",
   "metadata": {},
   "source": [
    "### Exercise 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ca3bd53f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "702\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "file = open('Datasets/year2017.csv')\n",
    "file_data = csv.reader(file)\n",
    "\n",
    "file_list = list(file_data)\n",
    "\n",
    "total = []\n",
    "for row in file_list[1:]:\n",
    "    if row[3]==\"India\":\n",
    "        val = row[10]\n",
    "        if val != '':\n",
    "            total.append(int(float(val)))\n",
    "\n",
    "print(sum(total))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "039a11e0",
   "metadata": {},
   "source": [
    "### Exercise 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "99e13f3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5465\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "with open('Datasets/year2017.csv') as file:\n",
    "    file_data = csv.DictReader(file)\n",
    "    \n",
    "    i=0\n",
    "    for row in file_data:\n",
    "        if row[\"Weapon_type\"] ==\"Explosives\":\n",
    "            i+=1\n",
    "        \n",
    "        \n",
    "print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5db6f0a",
   "metadata": {},
   "source": [
    "### Exercise 17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a40fb29b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1   2275\n",
      "2   2027\n",
      "3   2463\n",
      "4   2142\n",
      "5   2936\n",
      "6   2506\n",
      "7   2228\n",
      "8   2145\n",
      "9   1764\n",
      "10   2580\n",
      "11   2014\n",
      "12   1365\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "with open('Datasets/year2017.csv') as file_obj:\n",
    "    content = csv.DictReader(file_obj,skipinitialspace = True)\n",
    "    \n",
    "    dic = {}\n",
    "    for row in content:\n",
    "        key = row[\"Month\"]\n",
    "        value = row[\"Killed\"]\n",
    "        \n",
    "        if value !='':\n",
    "            value = int(float(value))\n",
    "        else:\n",
    "            value =0\n",
    "\n",
    "        if key in dic:\n",
    "            dic[key] += value\n",
    "        else:\n",
    "            dic[key] = value\n",
    "            \n",
    "\n",
    "for id, pair in dic.items():\n",
    "    print(id,\" \",pair)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf8eb9de",
   "metadata": {},
   "source": [
    "### Exercise 20.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e80dba8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "US, WA, Seattle \n",
      "IN, KA, Bangalore \n"
     ]
    },
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'charmap' codec can't decode byte 0x9d in position 4096: character maps to <undefined>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_2076\\146739642.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     26\u001b[0m     \u001b[0mcontent\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcsv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDictReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_obj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mskipinitialspace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mrow\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcontent\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m         \u001b[0mlocation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"location\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlocation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\csv.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    109\u001b[0m             \u001b[1;31m# Used only for its side effect.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfieldnames\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 111\u001b[1;33m         \u001b[0mrow\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    112\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mline_num\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mline_num\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\encodings\\cp1252.py\u001b[0m in \u001b[0;36mdecode\u001b[1;34m(self, input, final)\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mIncrementalDecoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcodecs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIncrementalDecoder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfinal\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mcodecs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcharmap_decode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdecoding_table\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mStreamWriter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mCodec\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcodecs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mStreamWriter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m: 'charmap' codec can't decode byte 0x9d in position 4096: character maps to <undefined>"
     ]
    }
   ],
   "source": [
    "# import csv\n",
    "# with open('Datasets/amazon_jobs_dataset.csv') as file_obj:\n",
    "#     content = csv.DictReader(file_obj,skipinitialspace = True)\n",
    "    \n",
    "#     blr = 0\n",
    "#     sea = 0\n",
    "#     for row in content:\n",
    "#         print(row[\"location\"])\n",
    "#         print()\n",
    "        \n",
    "#         if row[\"location\"] == \"IN, KA, Bangalore \":\n",
    "#             blr+=1\n",
    "#         elif row[\"location\"] == \"US, WA, Seattle \":\n",
    "#             sea +=1\n",
    "            \n",
    "            \n",
    "# print(blr,\" \",sea)\n",
    "\n",
    "\n",
    "import csv\n",
    "\n",
    "blr = 0\n",
    "sea = 0\n",
    "\n",
    "with open('Datasets/amazon_jobs_dataset.csv') as file_obj:\n",
    "    content = csv.DictReader(file_obj, skipinitialspace=True)\n",
    "\n",
    "    for row in content:\n",
    "        location = row[\"location\"]\n",
    "        print(location)\n",
    "\n",
    "        if \"IN, KA, Bangalore\" in location:\n",
    "            blr += 1\n",
    "        elif \"US, WA, Seattle\" in location:\n",
    "            sea += 1\n",
    "\n",
    "print(\"Bangalore:\", blr)\n",
    "print(\"Seattle:\", sea)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ce61eda",
   "metadata": {},
   "source": [
    "Getting this Error because of the encoding issue, \n",
    "- see in file i have so many accented characters.\n",
    "- so in this case what happens it, python is using system default encoding, usually \"cp1252\"\n",
    "- so we need to change it with the one which supports most of the characters.\n",
    "- UTF-8 supports wide range of characters so we will use it.\n",
    "\n",
    "- why we got error in the third line only, why not first and second, it also has accented characters\n",
    "- cp1252 is not like it doesnt supports accented characters at all, it decoded which as far as it can understand then when things went out of hand, and it was not able to decode, it raises error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "603e7b38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66   1856\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "blr = 0\n",
    "sea = 0\n",
    "\n",
    "with open('Datasets/amazon_jobs_dataset.csv',encoding='utf-8') as file_obj:\n",
    "    content = csv.DictReader(file_obj, skipinitialspace=True)\n",
    "    for row in content:\n",
    "        location = row[\"location\"]\n",
    "        \n",
    "        if \"IN, KA, Bangalore\" in location:\n",
    "            blr += 1\n",
    "        elif \"US, WA, Seattle\" in location:\n",
    "            sea += 1\n",
    "\n",
    "print(blr,\" \",sea)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f607fde3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "702 Software Development Engineer - Computer Vision\n",
      "703 Software Development Manager - Computer Vision\n",
      "860 Software Development Engineer - Computer Vision\n",
      "890 Senior Software Development Engineer - Computer Vision\n",
      "891 Senior Software Development Engineer - Computer Vision\n",
      "1036 Software Development Manager - Computer Vision\n",
      "1273 Computer Vision Applied Scientist\n",
      "1358 Software Development Engineer - Computer Vision\n",
      "1377 Software Development Engineer - Computer Vision\n",
      "1454 Principal Computer Vision Scientist\n",
      "1592 Software Development Engineer - Computer Vision Frameworks/Acceleration\n",
      "2500 Computer Vision and Deep Learning Research Scientist\n",
      "2661 Software Development Engineer - Computer Vision\n",
      "2662 Software Development Engineer - Computer Vision\n",
      "total :  14\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "count = 0\n",
    "i=0\n",
    "with open('Datasets/amazon_jobs_dataset.csv',encoding='utf-8') as file_obj:\n",
    "    content = csv.DictReader(file_obj, skipinitialspace=True)\n",
    "    for row in content:\n",
    "        var = row[\"Title\"]\n",
    "#         print(var)\n",
    "        i+=1\n",
    "        if \"Computer Vision\" in var:\n",
    "            count +=1\n",
    "            print(i, var)\n",
    "    \n",
    "print(\"total : \",count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c1849e94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "609\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "can = 0\n",
    "\n",
    "with open('Datasets/amazon_jobs_dataset.csv',encoding='utf-8') as file_obj:\n",
    "    content = csv.DictReader(file_obj, skipinitialspace=True)\n",
    "    for row in content:\n",
    "        location = row[\"location\"]\n",
    "        \n",
    "        if \"US, CA\" in location:\n",
    "            can += 1\n",
    "\n",
    "print(can)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6101d07e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "January 907\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "can = 0\n",
    "dic ={}\n",
    "mon = []\n",
    "with open('Datasets/amazon_jobs_dataset.csv',encoding='utf-8') as file_obj:\n",
    "    content = csv.DictReader(file_obj, skipinitialspace=True)\n",
    "    for row in content:\n",
    "        date = row[\"Posting_date\"]\n",
    "        list = date.split(\" \")\n",
    "        if list[-1]==\"2018\":\n",
    "            mon.append(list[0])\n",
    "            \n",
    "    for i in mon:\n",
    "        dic[i] = dic.get(i,0)+1\n",
    "            \n",
    "for id,pair in dic.items():\n",
    "    if pair==max(dic.values()):\n",
    "        print(id,pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9a63db05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2277\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "a =\"BA\"\n",
    "b =\"Bachelor\"\n",
    "c = \"BS\"\n",
    "count = 0\n",
    "with open('Datasets/amazon_jobs_dataset.csv',encoding='utf-8') as file_obj:\n",
    "    content = csv.DictReader(file_obj, skipinitialspace=True)\n",
    "    for row in content:\n",
    "        if (b or a or c) in row[\"BASIC QUALIFICATIONS\"]:\n",
    "            count +=1\n",
    "    \n",
    "print(count)\n",
    "                                               "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ce8aa38",
   "metadata": {},
   "source": [
    "## Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "929ee1b7",
   "metadata": {},
   "source": [
    "- this is not a reliable method, if (b or a or c) in row[\"BASIC QUALIFICATIONS\"]:\n",
    "- you should give complete statement with OR.\n",
    "- if b in row[\"BASIC QUALIFICATIONS\"] or a in row[\"BASIC QUALIFICATIONS\"] or c in row[\"BASIC QUALIFICATIONS\"]:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6173c1df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2961\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "a =\"BA\"\n",
    "b =\"Bachelor\"\n",
    "c = \"BS\"\n",
    "count = 0\n",
    "with open('Datasets/amazon_jobs_dataset.csv',encoding='utf-8') as file_obj:\n",
    "    content = csv.DictReader(file_obj, skipinitialspace=True)\n",
    "    for row in content:\n",
    "        if b in row[\"BASIC QUALIFICATIONS\"] or a in row[\"BASIC QUALIFICATIONS\"] or c in row[\"BASIC QUALIFICATIONS\"]:\n",
    "            count +=1\n",
    "    \n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a1f15891",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'US': 2027, 'IN': 114, 'CA': 113, 'RO': 9, 'PL': 17, 'AE': 1, 'ES': 13, 'IL': 2, 'DE': 19, 'UK': 40, 'SG': 1, 'AU': 9, 'IE': 30, 'CN': 14, 'MX': 2, 'NL': 2, 'ZA': 12, 'FR': 2, 'JO': 2, 'TW': 4, 'LU': 6, 'BR': 8, 'JP': 4, 'IT': 1}\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "d = \"java\"\n",
    "count = 0\n",
    "arr = [] \n",
    "di = {}\n",
    "with open('Datasets/amazon_jobs_dataset.csv',encoding='utf-8') as file_obj:\n",
    "    content = csv.DictReader(file_obj, skipinitialspace=True)\n",
    "    for row in content:\n",
    "        sentence = row[\"BASIC QUALIFICATIONS\"]\n",
    "        r = row[\"location\"]\n",
    "        new = sentence.lower()\n",
    "        if d in new:\n",
    "            if r[0:2] == '':\n",
    "                pass\n",
    "            else:\n",
    "                arr.append(r[0:2])\n",
    "            \n",
    "                        \n",
    "# print(arr)\n",
    "for i in arr:\n",
    "    di[i] = di.get(i,0)+1\n",
    "    \n",
    "print(di)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4a2196c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
